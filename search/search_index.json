{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>tablegpt-agent is a pre-built agent for TableGPT2 (huggingface), a series of LLMs for table-based question answering. This agent is built on top of the Langgraph library and provides a user-friendly interface for interacting with TableGPT2.</p>"},{"location":"#table-of-contents","title":"Table Of Contents","text":"<ul> <li>Tutorials<ul> <li>Quickstart</li> <li>Chat on Tabular Data</li> <li>Continue Analysis on Generated Charts</li> </ul> </li> <li>How-To Guides<ul> <li>Enhance TableGPT Agent with RAG</li> <li>Persist Messages</li> <li>Incluster Code Execution</li> <li>Normalize Datasets</li> </ul> </li> <li>Explanation<ul> <li>Agent Workflow</li> <li>File Reading</li> </ul> </li> <li>Reference</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Thank you for your interest in TableGPT Agent. For more information on contributing, please see the contributing guide.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>We extend our sincere gratitude to all contributors and collaborators who played a pivotal role in the development of tablegpt-agent. Special thanks to our team members and the open-source community, whose insights and feedback were invaluable throughout the project.</p> <p>Thank you to our early users for their suggestions and engagement, which have greatly helped in refining and enhancing this tool.</p>"},{"location":"reference/","title":"API Reference","text":"<p>Creates a state graph for processing datasets.</p> <p>This function orchestrates the creation of a workflow for handling table data. It sets up nodes for reading files and analyzing data based on provided parameters. The graph dynamically routes based on the presence of file attachments in the input state.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>Runnable</code> <p>The primary language model for processing user input.</p> required <code>pybox_manager</code> <code>BasePyBoxManager</code> <p>A python code sandbox delegator, used to execute the data analysis code generated by llm.</p> required <code>session_id</code> <code>str | None</code> <p>An optional session identifier used to associate with <code>pybox</code>. Defaults to None.</p> <code>None</code> <code>workdir</code> <code>Path | None</code> <p>The working directory for <code>pybox</code> operations. Defaults to None.</p> <code>None</code> <code>error_trace_cleanup</code> <code>bool</code> <p>Flag to clean up error traces. Defaults to False.</p> <code>False</code> <code>nlines</code> <code>int | None</code> <p>Number of lines to read for preview. Defaults to None.</p> <code>None</code> <code>vlm</code> <code>BaseLanguageModel | None</code> <p>Optional vision language model for processing images. Defaults to None.</p> <code>None</code> <code>safety_llm</code> <code>Runnable | None</code> <p>Model used for safety classification of inputs. Defaults to None.</p> <code>None</code> <code>dataset_retriever</code> <code>BaseRetriever | None</code> <p>Component to retrieve datasets. Defaults to None.</p> <code>None</code> <code>normalize_llm</code> <code>BaseLanguageModel | None</code> <p>Model for data normalization tasks. Defaults to None.</p> <code>None</code> <code>locate</code> <code>str | None</code> <p>The locale of the user. Defaults to None.</p> required <code>checkpointer</code> <code>BaseCheckpointSaver | None</code> <p>Component for saving checkpoints. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>CompiledStateGraph</code> <code>CompiledStateGraph</code> <p>A compiled state graph representing the table processing workflow.</p> Source code in <code>src/tablegpt/agent/__init__.py</code> <pre><code>def create_tablegpt_graph(\n    llm: BaseLanguageModel,\n    pybox_manager: BasePyBoxManager,\n    *,\n    session_id: str | None = None,\n    workdir: Path | None = None,\n    error_trace_cleanup: bool = False,\n    nlines: int | None = None,\n    vlm: BaseLanguageModel | None = None,\n    safety_llm: Runnable | None = None,\n    dataset_retriever: BaseRetriever | None = None,\n    normalize_llm: BaseLanguageModel | None = None,\n    locale: str | None = None,\n    checkpointer: BaseCheckpointSaver | None = None,\n    verbose: bool = False,\n) -&gt; CompiledStateGraph:\n    \"\"\"Creates a state graph for processing datasets.\n\n    This function orchestrates the creation of a workflow for handling table data.\n    It sets up nodes for reading files and analyzing data based on provided parameters.\n    The graph dynamically routes based on the presence of file attachments in the input state.\n\n    Args:\n        llm (Runnable): The primary language model for processing user input.\n        pybox_manager (BasePyBoxManager):  A python code sandbox delegator, used to execute the data analysis code generated by llm.\n        session_id (str | None, optional): An optional session identifier used to associate with `pybox`. Defaults to None.\n        workdir (Path | None, optional): The working directory for `pybox` operations. Defaults to None.\n        error_trace_cleanup (bool, optional): Flag to clean up error traces. Defaults to False.\n        nlines (int | None, optional): Number of lines to read for preview. Defaults to None.\n        vlm (BaseLanguageModel | None, optional): Optional vision language model for processing images. Defaults to None.\n        safety_llm (Runnable | None, optional): Model used for safety classification of inputs. Defaults to None.\n        dataset_retriever (BaseRetriever | None, optional): Component to retrieve datasets. Defaults to None.\n        normalize_llm (BaseLanguageModel | None, optional): Model for data normalization tasks. Defaults to None.\n        locate (str | None, optional): The locale of the user. Defaults to None.\n        checkpointer (BaseCheckpointSaver | None, optional): Component for saving checkpoints. Defaults to None.\n        verbose (bool, optional): Flag to enable verbose logging. Defaults to False.\n\n    Returns:\n        CompiledStateGraph: A compiled state graph representing the table processing workflow.\n    \"\"\"\n    workflow = StateGraph(AgentState)\n    file_reading_graph = create_file_reading_workflow(\n        nlines=nlines,\n        llm=llm,\n        pybox_manager=pybox_manager,\n        workdir=workdir,\n        session_id=session_id,\n        normalize_llm=normalize_llm,\n        locale=locale,\n        verbose=verbose,\n    )\n    data_analyze_graph = create_data_analyze_workflow(\n        llm=llm,\n        pybox_manager=pybox_manager,\n        workdir=workdir,\n        session_id=session_id,\n        error_trace_cleanup=error_trace_cleanup,\n        vlm=vlm,\n        safety_llm=safety_llm,\n        dataset_retriever=dataset_retriever,\n        verbose=verbose,\n    )\n\n    def router(state: AgentState) -&gt; str:\n        # Must have at least one message when entering this router\n        last_message = state[\"messages\"][-1]\n        if last_message.additional_kwargs.get(\"attachments\"):\n            return \"file_reading_graph\"\n        return \"data_analyze_graph\"\n\n    workflow.add_node(\"file_reading_graph\", file_reading_graph)\n    workflow.add_node(\"data_analyze_graph\", data_analyze_graph)\n\n    workflow.add_conditional_edges(START, router)\n    workflow.add_edge(\"file_reading_graph\", END)\n    workflow.add_edge(\"data_analyze_graph\", END)\n\n    return workflow.compile(checkpointer=checkpointer, debug=verbose)\n</code></pre>"},{"location":"explanation/agent-workflow/","title":"Agent Workflow","text":"<p>The Agent Workflow is the core functionality of the <code>tablegpt-agent</code>. It processes user input and generates appropriate responses. This workflow is similar to those found in most single-agent systems and consists of an agent and various tools. Specifically, the data analysis workflow includes:</p> <ul> <li>An Agent Powered by TableGPT2: This agent performs data analysis tasks.</li> <li>An IPython tool: This tool executes the generated code within a sandbox environment.</li> </ul> <p>Additionally, TableGPT Agent offers several optional plugins that extend the agent's functionality:</p> <ul> <li>A Visual Language Model that can be used to enhance summarization for data visualization tasks.</li> <li>A retriever that fetches information about the dataset, improving the quality and relevance of the generated code.</li> <li>A safety mechanism that protects the system from toxic inputs.</li> </ul>"},{"location":"explanation/file-reading/","title":"File Reading","text":"<p>TableGPT Agent separates the file reading workflow from the data analysis workflow to maintain greater control over how the LLM inspects the dataset files. Typically, if you let the LLM inspect the dataset itself, it uses the <code>df.head()</code> function to preview the data. While this is sufficient for basic cases, we have implemented a more structured approach by hard-coding the file reading workflow into several steps:</p> <ul> <li><code>normalization</code> (optional): For some Excel files, the content may not be 'pandas-friendly'. We include an optional normalization step to transform the Excel content into a more suitable format for pandas.</li> <li><code>df.info()</code>: Unlike <code>df.head()</code>, <code>df.info()</code> provides insights into the dataset's structure, such as the data types of each column and the number of non-null values, which also indicates whether a column contains NaN. This insight helps the LLM understand the structure and quality of the data.</li> <li><code>df.head()</code>: The final step displays the first n rows of the dataset, where n is configurable. A larger value for n allows the LLM to glean more information from the dataset; however, too much detail may divert its attention from the primary task.</li> </ul>"},{"location":"howto/incluster-code-execution/","title":"Incluster Code Execution","text":"<p>The <code>tablegpt-agent</code> directs <code>tablegpt</code> to generate Python code for data analysis. This code is then executed within a sandbox environment to ensure system security. The execution is managed by the pybox library, which provides a simple way to run Python code outside the main process.</p>"},{"location":"howto/incluster-code-execution/#usage","title":"Usage","text":"<p>If you're using the local executor (pybox.LocalPyBoxManager), follow these steps to configure the environment:</p> <ol> <li> <p>Install the dependencies required for the <code>IPython Kernel</code> using the following command:</p> <pre><code>pip install -r ipython/requirements.txt\n</code></pre> </li> <li> <p>Copy the code from the <code>ipython/ipython-startup-scripts</code> folder to the <code>$HOME/.ipython/profile_default/startup/</code> directory.</p> <p>This folder contains the functions and configurations needed to perform data analysis with <code>tablegpt-agent</code>.</p> <p>Note: The <code>~/.ipython</code> directory must be writable for the process launching the kernel, otherwise there will be a warning message: <code>UserWarning: IPython dir '/home/jovyan/.ipython' is not a writable location, using a temp directory.</code> and the startup scripts won't take effects.</p> </li> </ol>"},{"location":"howto/normalize-datasets/","title":"Normalize Datasets","text":"<p>The <code>Dataset Normalizer</code> plugin is used to transform 'pandas-unfriendly' datasets (e.g., Excel files that do not follow a standard tabular structure) into a more suitable format for pandas. It is backed by an LLM that generates Python code to convert the original datasets into new ones.</p> <p>In <code>tablegpt-agent</code>, this plugin is used to better format 'pandas-unfriendly' datasets, making them more understandable for the subsequent steps. This plugin is optional; if used, it serves as the very first step in the File Reading workflow, easing the difficulty of data analysis in the subsequent workflow.</p>"},{"location":"howto/persist-messages/","title":"Persist Messages","text":"In\u00a0[\u00a0]: Copied! <pre>from datetime import date\n\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom tablegpt.agent import create_tablegpt_graph\nfrom pybox import LocalPyBoxManager\n\nllm = ChatOpenAI(openai_api_base=\"YOUR_VLLM_URL\", openai_api_key=\"whatever\", model_name=\"TableGPT2-7B\")\npybox_manager = LocalPyBoxManager()\ncheckpointer = MemorySaver()\n\ngraph = create_tablegpt_graph(\n    llm=llm,\n    pybox_manager=pybox_manager,\n    checkpointer=checkpointer,\n)\n</pre> from datetime import date  from langchain_openai import ChatOpenAI from langgraph.checkpoint.memory import MemorySaver from tablegpt.agent import create_tablegpt_graph from pybox import LocalPyBoxManager  llm = ChatOpenAI(openai_api_base=\"YOUR_VLLM_URL\", openai_api_key=\"whatever\", model_name=\"TableGPT2-7B\") pybox_manager = LocalPyBoxManager() checkpointer = MemorySaver()  graph = create_tablegpt_graph(     llm=llm,     pybox_manager=pybox_manager,     checkpointer=checkpointer, ) <p>Conducting a Conversation with <code>TableGPT</code></p> In\u00a0[2]: Copied! <pre>resp = await graph.ainvoke(\n    input={\n        \"messages\": [(\"human\", \"Please introduce Jackie Chan\")],\n        \"parent_id\": \"1\",\n        \"date\": date.today(),\n    },\n    config={\"configurable\": {\"thread_id\": \"1\"}},\n)\nresp[\"messages\"][-1]\n</pre> resp = await graph.ainvoke(     input={         \"messages\": [(\"human\", \"Please introduce Jackie Chan\")],         \"parent_id\": \"1\",         \"date\": date.today(),     },     config={\"configurable\": {\"thread_id\": \"1\"}}, ) resp[\"messages\"][-1] Out[2]: <pre>AIMessage(content=\"I understand that you're asking for an introduction to Jackie Chan. However, my primary role is to analyze datasets using Python. If you have a dataset related to Jackie Chan or any other topic, I'd be happy to help you analyze it. Could you please provide more details on what kind of data you have or what specific analysis you would like to perform?\", additional_kwargs={'parent_id': '1'}, response_metadata={}, id='cdf638ce-0e56-475b-a86b-0d8d7a0f6d05')</pre> <p>Continuing the Conversation</p> <p>To extend the conversation while maintaining context, you can provide new input along with the same <code>config</code> configuration:</p> <p>Note: <code>config</code> is the configuration associated with this <code>checkpointer</code>. Through this configuration, the <code>checkpointer</code> can retrieve previous status information, so that in subsequent conversations, the model can better understand the user's intention and reply.</p> In\u00a0[3]: Copied! <pre>resp = await graph.ainvoke(\n    input={\n        \"messages\": [(\"human\", \"Please name three movies he participated in.\")],\n        \"parent_id\": \"1\",\n        \"date\": date.today(),\n    },\n    config={\"configurable\": {\"thread_id\": \"1\"}},\n)\nresp[\"messages\"][-1]\n</pre> resp = await graph.ainvoke(     input={         \"messages\": [(\"human\", \"Please name three movies he participated in.\")],         \"parent_id\": \"1\",         \"date\": date.today(),     },     config={\"configurable\": {\"thread_id\": \"1\"}}, ) resp[\"messages\"][-1] Out[3]: <pre>AIMessage(content=\"Certainly! Jackie Chan is a renowned actor, director, and martial artist, and he has starred in numerous films. Here are three popular movies in which he has participated:\\n\\n1. **Rush Hour (1998)** - In this action-comedy film, Jackie Chan plays the role of Inspector Lee, a Hong Kong detective who teams up with a Los Angeles detective, played by Chris Tucker, to solve a kidnapping case.\\n\\n2. **Drunken Master (1978)** - This is one of Jackie Chan's early films where he plays a young man who learns the art of drunken boxing to avenge his father's enemies.\\n\\n3. **The Karate Kid (2010)** - In this remake of the original 1984 film, Jackie Chan plays Mr. Han, a maintenance man who becomes the mentor to a young boy, Jaden Smith, teaching him martial arts and life lessons.\\n\\nIf you have any specific data or analysis related to these movies or Jackie Chan's filmography, feel free to provide more details, and I can help you with that!\", additional_kwargs={'parent_id': '1'}, response_metadata={}, id='4f62bec2-a4ec-43ad-97b2-cbade8c774b4')</pre> <p>Next, we demonstrates how to use <code>Postgres</code> as the backend for persisting checkpoint state using the langgraph-checkpoint-postgres library.</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U psycopg psycopg-pool psycopg_binary langgraph langgraph-checkpoint-postgres\n</pre> %pip install -U psycopg psycopg-pool psycopg_binary langgraph langgraph-checkpoint-postgres In\u00a0[4]: Copied! <pre>DB_URI = \"postgresql://postgres:postgres@postgres.postgres-shared.svc.cluster.local:5432/postgres?sslmode=disable\"\n</pre> DB_URI = \"postgresql://postgres:postgres@postgres.postgres-shared.svc.cluster.local:5432/postgres?sslmode=disable\" In\u00a0[5]: Copied! <pre>from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\nfrom tablegpt.agent import create_tablegpt_graph\n\nconfig = {\"configurable\": {\"thread_id\": \"2\"}}\n\nasync with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:\n    graph = create_tablegpt_graph(\n        llm=llm,\n        pybox_manager=pybox_manager,\n        checkpointer=checkpointer,\n    )\n    \n    res = await graph.ainvoke(\n        input={\n            \"messages\": [(\"human\", \"Who are you?\")],\n            \"parent_id\": \"2\",\n            \"date\": date.today()\n        },\n        config=config,\n    )\n    checkpoint_tuples = [c async for c in checkpointer.alist(config)]\n</pre> from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver from tablegpt.agent import create_tablegpt_graph  config = {\"configurable\": {\"thread_id\": \"2\"}}  async with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:     graph = create_tablegpt_graph(         llm=llm,         pybox_manager=pybox_manager,         checkpointer=checkpointer,     )          res = await graph.ainvoke(         input={             \"messages\": [(\"human\", \"Who are you?\")],             \"parent_id\": \"2\",             \"date\": date.today()         },         config=config,     )     checkpoint_tuples = [c async for c in checkpointer.alist(config)] In\u00a0[6]: Copied! <pre>checkpoint_tuples\n</pre> checkpoint_tuples Out[6]: <pre>[CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-5d51-63c3-8001-9bd42cf9d6e6'}}, checkpoint={'v': 1, 'id': '1efa6543-5d51-63c3-8001-9bd42cf9d6e6', 'ts': '2024-11-19T08:56:48.239486+00:00', 'pending_sends': [], 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.6926057190269731'}, 'data_analyze_graph': {'branch:__start__:router:data_analyze_graph': '00000000000000000000000000000002.0.32407437506283565'}}, 'channel_versions': {'date': '00000000000000000000000000000003.0.1780977977687367', 'messages': '00000000000000000000000000000003.0.05509702188973753', '__start__': '00000000000000000000000000000002.3.0886787893869005e-05', 'parent_id': '00000000000000000000000000000003.0.43858547879187637', 'data_analyze_graph': '00000000000000000000000000000003.0.1082481333441786', 'branch:__start__:router:data_analyze_graph': '00000000000000000000000000000003.0.593567034515958'}, 'channel_values': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930'), AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')], 'parent_id': '2', 'data_analyze_graph': 'data_analyze_graph'}}, metadata={'step': 1, 'source': 'loop', 'writes': {'data_analyze_graph': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930'), AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')], 'parent_id': '2'}}, 'parents': {}, 'thread_id': '2'}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}}, pending_writes=[]),\n CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-5d27-6b37-8002-4e274906f4a5'}}, checkpoint={'v': 1, 'id': '1efa6543-5d27-6b37-8002-4e274906f4a5', 'ts': '2024-11-19T08:56:48.222457+00:00', 'pending_sends': [], 'versions_seen': {'agent': {'join:input_guard+retrieve_columns:agent': '00000000000000000000000000000003.0.8898909183470118'}, '__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.6163867462467301'}, 'input_guard': {'start:input_guard': '00000000000000000000000000000002.0.6848611387807798'}, 'retrieve_columns': {'start:retrieve_columns': '00000000000000000000000000000002.0.030416452982199194'}}, 'channel_versions': {'date': '00000000000000000000000000000002.0.2490273362085793', 'agent': '00000000000000000000000000000005.0.024232530645486583', 'messages': '00000000000000000000000000000005.0.14282746367420773', '__start__': '00000000000000000000000000000002.0.18620036399153372', 'parent_id': '00000000000000000000000000000002.0.5201095646733788', 'input_guard': '00000000000000000000000000000005.0.859473129275239', 'retrieve_columns': '00000000000000000000000000000005.0.7752176585300508', 'start:input_guard': '00000000000000000000000000000003.0.6183120254220215', 'start:retrieve_columns': '00000000000000000000000000000003.0.08187600687354024', 'join:input_guard+retrieve_columns:agent': '00000000000000000000000000000004.0.5107824581933167'}, 'channel_values': {'date': datetime.date(2024, 11, 19), 'agent': 'agent', 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930'), AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')], 'parent_id': '2', 'join:input_guard+retrieve_columns:agent': set()}}, metadata={'step': 2, 'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')]}}, 'parents': {'': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}, 'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'langgraph_node': 'data_analyze_graph', 'langgraph_path': ['__pregel_pull', 'data_analyze_graph'], 'langgraph_step': 1, 'langgraph_triggers': ['branch:__start__:router:data_analyze_graph'], 'langgraph_checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd'}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-4a53-6aa4-8001-7474db32528e'}}, pending_writes=[]),\n CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-4a53-6aa4-8001-7474db32528e'}}, checkpoint={'v': 1, 'id': '1efa6543-4a53-6aa4-8001-7474db32528e', 'ts': '2024-11-19T08:56:46.248182+00:00', 'pending_sends': [], 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.6163867462467301'}, 'input_guard': {'start:input_guard': '00000000000000000000000000000002.0.6848611387807798'}, 'retrieve_columns': {'start:retrieve_columns': '00000000000000000000000000000002.0.030416452982199194'}}, 'channel_versions': {'date': '00000000000000000000000000000002.0.2490273362085793', 'messages': '00000000000000000000000000000003.0.8478737633204881', '__start__': '00000000000000000000000000000002.0.18620036399153372', 'parent_id': '00000000000000000000000000000002.0.5201095646733788', 'input_guard': '00000000000000000000000000000003.0.06039244147872136', 'retrieve_columns': '00000000000000000000000000000003.0.8552403538042089', 'start:input_guard': '00000000000000000000000000000003.0.6183120254220215', 'start:retrieve_columns': '00000000000000000000000000000003.0.08187600687354024', 'join:input_guard+retrieve_columns:agent': '00000000000000000000000000000003.0.8898909183470118'}, 'channel_values': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930')], 'parent_id': '2', 'input_guard': 'input_guard', 'retrieve_columns': 'retrieve_columns', 'join:input_guard+retrieve_columns:agent': {'input_guard', 'retrieve_columns'}}}, metadata={'step': 1, 'source': 'loop', 'writes': {'input_guard': {'messages': []}, 'retrieve_columns': {'messages': []}}, 'parents': {'': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}, 'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'langgraph_node': 'data_analyze_graph', 'langgraph_path': ['__pregel_pull', 'data_analyze_graph'], 'langgraph_step': 1, 'langgraph_triggers': ['branch:__start__:router:data_analyze_graph'], 'langgraph_checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd'}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-4a4c-6639-8000-a5baf4d38bd2'}}, pending_writes=[('36d7d700-5338-feda-05f0-57d74fddbc0b', 'agent', 'agent'), ('36d7d700-5338-feda-05f0-57d74fddbc0b', 'messages', [AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')])]),\n CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-4a4c-6639-8000-a5baf4d38bd2'}}, checkpoint={'v': 1, 'id': '1efa6543-4a4c-6639-8000-a5baf4d38bd2', 'ts': '2024-11-19T08:56:46.245208+00:00', 'pending_sends': [], 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.6163867462467301'}}, 'channel_versions': {'date': '00000000000000000000000000000002.0.2490273362085793', 'messages': '00000000000000000000000000000002.0.19507603965774079', '__start__': '00000000000000000000000000000002.0.18620036399153372', 'parent_id': '00000000000000000000000000000002.0.5201095646733788', 'start:input_guard': '00000000000000000000000000000002.0.6848611387807798', 'start:retrieve_columns': '00000000000000000000000000000002.0.030416452982199194'}, 'channel_values': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930')], 'parent_id': '2', 'start:input_guard': '__start__', 'start:retrieve_columns': '__start__'}}, metadata={'step': 0, 'source': 'loop', 'writes': None, 'parents': {'': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}, 'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'langgraph_node': 'data_analyze_graph', 'langgraph_path': ['__pregel_pull', 'data_analyze_graph'], 'langgraph_step': 1, 'langgraph_triggers': ['branch:__start__:router:data_analyze_graph'], 'langgraph_checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd'}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-4a49-6ec0-bfff-7a6bdf830d6b'}}, pending_writes=[('637b8d5c-1e9a-d15c-7560-eba440c88860', 'input_guard', 'input_guard'), ('637b8d5c-1e9a-d15c-7560-eba440c88860', 'messages', []), ('637b8d5c-1e9a-d15c-7560-eba440c88860', 'join:input_guard+retrieve_columns:agent', 'input_guard'), ('fcc182eb-567e-cef1-c5be-16b527e21434', 'retrieve_columns', 'retrieve_columns'), ('fcc182eb-567e-cef1-c5be-16b527e21434', 'messages', []), ('fcc182eb-567e-cef1-c5be-16b527e21434', 'join:input_guard+retrieve_columns:agent', 'retrieve_columns')]),\n CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'checkpoint_id': '1efa6543-4a49-6ec0-bfff-7a6bdf830d6b'}}, checkpoint={'v': 1, 'id': '1efa6543-4a49-6ec0-bfff-7a6bdf830d6b', 'ts': '2024-11-19T08:56:46.244206+00:00', 'pending_sends': [], 'versions_seen': {'__input__': {}}, 'channel_versions': {'__start__': '00000000000000000000000000000001.0.6163867462467301'}, 'channel_values': {'__start__': {'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930')], 'parent_id': '2', 'date': datetime.date(2024, 11, 19)}}}, metadata={'step': -1, 'source': 'input', 'writes': {'__start__': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930')], 'parent_id': '2'}}, 'parents': {'': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}, 'thread_id': '2', 'checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'langgraph_node': 'data_analyze_graph', 'langgraph_path': ['__pregel_pull', 'data_analyze_graph'], 'langgraph_step': 1, 'langgraph_triggers': ['branch:__start__:router:data_analyze_graph'], 'langgraph_checkpoint_ns': 'data_analyze_graph:3d6fb60f-4da5-a1de-bcf2-fa5632547abd'}, parent_config=None, pending_writes=[('39da96de-984e-3d02-e2ef-9bd5146d7336', 'messages', [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930')]), ('39da96de-984e-3d02-e2ef-9bd5146d7336', 'date', datetime.date(2024, 11, 19)), ('39da96de-984e-3d02-e2ef-9bd5146d7336', 'parent_id', '2'), ('39da96de-984e-3d02-e2ef-9bd5146d7336', 'start:input_guard', '__start__'), ('39da96de-984e-3d02-e2ef-9bd5146d7336', 'start:retrieve_columns', '__start__')]),\n CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}}, checkpoint={'v': 1, 'id': '1efa6543-4a1a-6852-8000-b975c65fb2ff', 'ts': '2024-11-19T08:56:46.224784+00:00', 'pending_sends': [], 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.6926057190269731'}}, 'channel_versions': {'date': '00000000000000000000000000000002.0.602279509708772', 'messages': '00000000000000000000000000000002.0.47212683047327253', '__start__': '00000000000000000000000000000002.3.0886787893869005e-05', 'parent_id': '00000000000000000000000000000002.0.43326965052986344', 'branch:__start__:router:data_analyze_graph': '00000000000000000000000000000002.0.32407437506283565'}, 'channel_values': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930')], 'parent_id': '2', 'branch:__start__:router:data_analyze_graph': '__start__'}}, metadata={'step': 0, 'source': 'loop', 'writes': None, 'parents': {}, 'thread_id': '2'}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-4a12-6bbb-bfff-ac4aee846bfe'}}, pending_writes=[('3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'data_analyze_graph', 'data_analyze_graph'), ('3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'messages', [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930'), AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')]), ('3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'parent_id', '2'), ('3d6fb60f-4da5-a1de-bcf2-fa5632547abd', 'date', datetime.date(2024, 11, 19))]),\n CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-4a12-6bbb-bfff-ac4aee846bfe'}}, checkpoint={'v': 1, 'id': '1efa6543-4a12-6bbb-bfff-ac4aee846bfe', 'ts': '2024-11-19T08:56:46.221598+00:00', 'pending_sends': [], 'versions_seen': {'__input__': {}}, 'channel_versions': {'__start__': '00000000000000000000000000000001.0.6926057190269731'}, 'channel_values': {'__start__': {'messages': [['human', 'Who are you?']], 'parent_id': '2', 'date': datetime.date(2024, 11, 19)}}}, metadata={'step': -1, 'source': 'input', 'writes': {'__start__': {'date': datetime.date(2024, 11, 19), 'messages': [['human', 'Who are you?']], 'parent_id': '2'}}, 'parents': {}, 'thread_id': '2'}, parent_config=None, pending_writes=[('8e27b3ac-0a9d-697e-0667-6d3ccc170a50', 'messages', [['human', 'Who are you?']]), ('8e27b3ac-0a9d-697e-0667-6d3ccc170a50', 'parent_id', '2'), ('8e27b3ac-0a9d-697e-0667-6d3ccc170a50', 'date', datetime.date(2024, 11, 19)), ('8e27b3ac-0a9d-697e-0667-6d3ccc170a50', 'branch:__start__:router:data_analyze_graph', '__start__')])]</pre> In\u00a0[7]: Copied! <pre>async with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:\n    graph = create_tablegpt_graph(\n        llm=llm,\n        pybox_manager=pybox_manager,\n        checkpointer=checkpointer,\n    )\n    \n    graph_state = await graph.aget_state(config)\n</pre> async with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:     graph = create_tablegpt_graph(         llm=llm,         pybox_manager=pybox_manager,         checkpointer=checkpointer,     )          graph_state = await graph.aget_state(config) In\u00a0[8]: Copied! <pre>graph_state\n</pre> graph_state Out[8]: <pre>StateSnapshot(values={'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930'), AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')], 'parent_id': '2', 'date': datetime.date(2024, 11, 19)}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-5d51-63c3-8001-9bd42cf9d6e6'}}, metadata={'step': 1, 'source': 'loop', 'writes': {'data_analyze_graph': {'date': datetime.date(2024, 11, 19), 'messages': [HumanMessage(content='Who are you?', additional_kwargs={}, response_metadata={}, id='32b67f59-d13e-43eb-9239-ec711811e930'), AIMessage(content=\"I am TableGPT2, an expert Python data analyst developed by Zhejiang University. My primary role is to assist you in analyzing datasets by writing Python code. I can help you with tasks such as data cleaning, transformation, visualization, and more. If you have a dataset or a specific analysis in mind, feel free to share it with me, and I'll do my best to help you!\", additional_kwargs={'parent_id': '2'}, response_metadata={}, id='560a88be-4fd0-4cc1-aa55-0747862fa222')], 'parent_id': '2'}}, 'parents': {}, 'thread_id': '2'}, created_at='2024-11-19T08:56:48.239486+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efa6543-4a1a-6852-8000-b975c65fb2ff'}}, tasks=())</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"howto/persist-messages/#persist-messages","title":"Persist Messages\u00b6","text":"<p>When creating TableGPT agents, you have the option to persist their state, enabling interactions with the agent across multiple sessions while retaining memory of previous interactions. For more information on persistence, you can refer to the Persistence documentation.</p> <p>The benefit of persistent messages is that you can interact with the TableGPT agent across multiple sessions, and the agent remembers previous interactions. This is useful for applications that require long-term tracking of context or complex conversations.</p> <p>TableGPT Agent leverages langgraph-checkpoint to implement persistent message storage. It supports using any type of <code>checkpointer</code> to store messages, such as: <code>Postgres</code>, <code>Redis</code>, <code>Memory</code>, etc. To integrate a checkpointer with a <code>TableGPT Agent</code>, you can follow the example below:</p>"},{"location":"howto/persist-messages/#installing-required-packages","title":"Installing Required Packages\u00b6","text":""},{"location":"howto/persist-messages/#use-async-connection","title":"Use Async Connection\u00b6","text":"<p>Note: <code>TableGPT Agent</code> is built based on LangGraph, and many of the <code>Node</code> components use <code>async/await</code> syntax, which does not yet support non-asynchronous operations.</p> <p>Setting up an asynchronous connection to the database allows for non-blocking database operations. This means other parts of your application can continue running while waiting for database operations to complete. This is particularly beneficial in high-concurrency scenarios or when dealing with I/O-bound operations.</p> <p>The <code>DB_URI</code> is the database connection URI, specifying the protocol for connecting to a PostgreSQL database, including authentication and the host where the database is running.</p>"},{"location":"howto/persist-messages/#creating-a-checkpointer-with-asyncpostgressaver","title":"Creating a Checkpointer with AsyncPostgresSaver\u00b6","text":"<p>This creates a connection based on a connection string:</p> <ul> <li>Advantages: Simplicity, encapsulates connection details</li> <li>Best for: Quick setup or when connection details are provided as a string</li> </ul>"},{"location":"howto/persist-messages/#get-persisted-messages-with-config","title":"Get Persisted Messages with Config\u00b6","text":"<p>We can use the same config parameters to retrieve persisted messages through the <code>checkpointer</code>. You can follow the example below:</p>"},{"location":"howto/retrieval/","title":"Enhance TableGPT Agent with RAG","text":"<p>While the File Reading Workflow is adequate for most scenarios, it may not always provide the information necessary for the LLM to generate accurate code. Consider the following examples:</p> <ul> <li>A categorical column in the dataset contains 'foo', 'bar', and 'baz', but 'baz' only appears after approximately 100 rows. In this case, the LLM may not encounter the 'baz' value through <code>df.head()</code>.</li> <li>The user's query may not align with the dataset's content for several reasons:</li> <li>The dataset lacks proper governance. For instance, a cell value might be misspelled from 'foo' to 'fou'.</li> <li>There could be a typo in the user's query. For example, if the user queries, \"Show me the data for 'fou',\" but the dataset contains 'foo' instead.</li> </ul> <p>In such situations, the Dataset Retriever plugin can be utilized to fetch additional information about the dataset from external sources, thereby providing the LLM with more context and improving its ability to generate accurate responses.</p>"},{"location":"tutorials/chat-on-tabular-data/","title":"Chat on Tabular Data","text":"In\u00a0[5]: Copied! <pre>from langgraph.checkpoint.memory import MemorySaver\n\ncheckpointer = MemorySaver()\nagent = create_tablegpt_graph(\n    llm=llm,\n    pybox_manager=pybox_manager,\n    checkpointer=checkpointer,\n    session_id=\"some-session-id\",\n)\n</pre> from langgraph.checkpoint.memory import MemorySaver  checkpointer = MemorySaver() agent = create_tablegpt_graph(     llm=llm,     pybox_manager=pybox_manager,     checkpointer=checkpointer,     session_id=\"some-session-id\", ) <p>Add the file for processing in the additional_kwargs of HumanMessage. Here's an example using the Titanic dataset.</p> In\u00a0[6]: Copied! <pre>from typing import TypedDict\nfrom langchain_core.messages import HumanMessage\n\nclass Attachment(TypedDict):\n    \"\"\"Contains at least one dictionary with the key filename.\"\"\"\n    filename: str\n\nattachment_msg = HumanMessage(\n    content=\"\",\n    # Please make sure your iPython kernel can access your filename.\n    additional_kwargs={\"attachments\": [Attachment(filename=\"titanic.csv\")]},\n)\n</pre> from typing import TypedDict from langchain_core.messages import HumanMessage  class Attachment(TypedDict):     \"\"\"Contains at least one dictionary with the key filename.\"\"\"     filename: str  attachment_msg = HumanMessage(     content=\"\",     # Please make sure your iPython kernel can access your filename.     additional_kwargs={\"attachments\": [Attachment(filename=\"titanic.csv\")]}, ) <p>Invoke the agent as shown in the quick start:</p> In\u00a0[7]: Copied! <pre>from datetime import date\nfrom tablegpt.agent.file_reading import Stage\n\n# Reading and processing files.\nresponse = await agent.ainvoke(\n    input={\n        \"entry_message\": attachment_msg,\n        \"processing_stage\": Stage.UPLOADED,\n        \"messages\": [attachment_msg],\n        \"parent_id\": \"some-parent-id1\",\n        \"date\": date.today(),\n    },\n    config={\n        # Using checkpointer requires binding thread_id at runtime.\n        \"configurable\": {\"thread_id\": \"some-thread-id\"},\n    },\n)\nresponse[\"messages\"]\n</pre> from datetime import date from tablegpt.agent.file_reading import Stage  # Reading and processing files. response = await agent.ainvoke(     input={         \"entry_message\": attachment_msg,         \"processing_stage\": Stage.UPLOADED,         \"messages\": [attachment_msg],         \"parent_id\": \"some-parent-id1\",         \"date\": date.today(),     },     config={         # Using checkpointer requires binding thread_id at runtime.         \"configurable\": {\"thread_id\": \"some-thread-id\"},     }, ) response[\"messages\"] Out[7]: <pre>[HumanMessage(content='', additional_kwargs={'attachments': [{'filename': 'titanic.csv'}]}, response_metadata={}, id='ab0a7157-ad7d-4de8-9b24-1bee78ad7c55'),\n AIMessage(content=\"\u6211\u5df2\u7ecf\u6536\u5230\u60a8\u7684\u6570\u636e\u6587\u4ef6\uff0c\u6211\u9700\u8981\u67e5\u770b\u6587\u4ef6\u5185\u5bb9\u4ee5\u5bf9\u6570\u636e\u96c6\u6709\u4e00\u4e2a\u521d\u6b65\u7684\u4e86\u89e3\u3002\u9996\u5148\u6211\u4f1a\u8bfb\u53d6\u6570\u636e\u5230 `df` \u53d8\u91cf\u4e2d\uff0c\u5e76\u901a\u8fc7 `df.info` \u67e5\u770b NaN \u60c5\u51b5\u548c\u6570\u636e\u7c7b\u578b\u3002\\n```python\\n# Load the data into a DataFrame\\ndf = read_df('titanic.csv')\\n\\n# Remove leading and trailing whitespaces in column names\\ndf.columns = df.columns.str.strip()\\n\\n# Remove rows and columns that contain only empty values\\ndf = df.dropna(how='all').dropna(axis=1, how='all')\\n\\n# Get the basic information of the dataset\\ndf.info(memory_usage=False)\\n```\", additional_kwargs={'parent_id': 'some-parent-id1', 'thought': '\u6211\u5df2\u7ecf\u6536\u5230\u60a8\u7684\u6570\u636e\u6587\u4ef6\uff0c\u6211\u9700\u8981\u67e5\u770b\u6587\u4ef6\u5185\u5bb9\u4ee5\u5bf9\u6570\u636e\u96c6\u6709\u4e00\u4e2a\u521d\u6b65\u7684\u4e86\u89e3\u3002\u9996\u5148\u6211\u4f1a\u8bfb\u53d6\u6570\u636e\u5230 `df` \u53d8\u91cf\u4e2d\uff0c\u5e76\u901a\u8fc7 `df.info` \u67e5\u770b NaN \u60c5\u51b5\u548c\u6570\u636e\u7c7b\u578b\u3002', 'action': {'tool': 'python', 'tool_input': \"# Load the data into a DataFrame\\ndf = read_df('titanic.csv')\\n\\n# Remove leading and trailing whitespaces in column names\\ndf.columns = df.columns.str.strip()\\n\\n# Remove rows and columns that contain only empty values\\ndf = df.dropna(how='all').dropna(axis=1, how='all')\\n\\n# Get the basic information of the dataset\\ndf.info(memory_usage=False)\"}, 'model_type': None}, response_metadata={}, id='add6691d-d7ea-411d-9699-e99ae0b7de97', tool_calls=[{'name': 'python', 'args': {'query': \"# Load the data into a DataFrame\\ndf = read_df('titanic.csv')\\n\\n# Remove leading and trailing whitespaces in column names\\ndf.columns = df.columns.str.strip()\\n\\n# Remove rows and columns that contain only empty values\\ndf = df.dropna(how='all').dropna(axis=1, how='all')\\n\\n# Get the basic information of the dataset\\ndf.info(memory_usage=False)\"}, 'id': 'b846aa01-04ef-4669-9a5c-53ddcb9a2dfb', 'type': 'tool_call'}]),\n ToolMessage(content=[{'type': 'text', 'text': \"```pycon\\n&lt;class 'pandas.core.frame.DataFrame'&gt;\\nRangeIndex: 4 entries, 0 to 3\\nData columns (total 8 columns):\\n #   Column    Non-Null Count  Dtype  \\n---  ------    --------------  -----  \\n 0   Pclass    4 non-null      int64  \\n 1   Sex       4 non-null      object \\n 2   Age       4 non-null      float64\\n 3   SibSp     4 non-null      int64  \\n 4   Parch     4 non-null      int64  \\n 5   Fare      4 non-null      float64\\n 6   Embarked  4 non-null      object \\n 7   Survived  4 non-null      int64  \\ndtypes: float64(2), int64(4), object(2)\\n```\"}], name='python', id='0d441b21-bff3-463c-a07f-c0b12bd17bc5', tool_call_id='b846aa01-04ef-4669-9a5c-53ddcb9a2dfb', artifact=[]),\n AIMessage(content='\u63a5\u4e0b\u6765\u6211\u5c06\u7528 `df.head(5)` \u6765\u67e5\u770b\u6570\u636e\u96c6\u7684\u524d 5 \u884c\u3002\\n```python\\n# Show the first 5 rows to understand the structure\\ndf.head(5)\\n```', additional_kwargs={'parent_id': 'some-parent-id1', 'thought': '\u63a5\u4e0b\u6765\u6211\u5c06\u7528 `df.head(5)` \u6765\u67e5\u770b\u6570\u636e\u96c6\u7684\u524d 5 \u884c\u3002', 'action': {'tool': 'python', 'tool_input': '# Show the first 5 rows to understand the structure\\ndf.head(5)'}, 'model_type': None}, response_metadata={}, id='5e26ef1d-7042-471e-b39f-194a51a185c7', tool_calls=[{'name': 'python', 'args': {'query': '# Show the first 5 rows to understand the structure\\ndf.head(5)'}, 'id': 'f6be0d96-05b3-4b5b-8313-90197a8c3d87', 'type': 'tool_call'}]),\n ToolMessage(content=[{'type': 'text', 'text': '```pycon\\n   Pclass     Sex   Age  SibSp  Parch    Fare Embarked  Survived\\n0       2  female  29.0      0      2  23.000        S         1\\n1       3  female  39.0      1      5  31.275        S         0\\n2       3    male  26.5      0      0   7.225        C         0\\n3       3    male  32.0      0      0  56.496        S         1\\n```'}], name='python', id='6fc6d8aa-546c-467e-91d3-d57b0b62dd68', tool_call_id='f6be0d96-05b3-4b5b-8313-90197a8c3d87', artifact=[]),\n AIMessage(content='\u6211\u5df2\u7ecf\u4e86\u89e3\u4e86\u6570\u636e\u96c6 titanic.csv \u7684\u57fa\u672c\u4fe1\u606f\u3002\u8bf7\u95ee\u6211\u53ef\u4ee5\u5e2e\u60a8\u505a\u4e9b\u4ec0\u4e48\uff1f', additional_kwargs={'parent_id': 'some-parent-id1'}, response_metadata={}, id='b6dc3885-94cb-4b0f-b691-f37c4c8c9ba3')]</pre> <p>Continue to ask questions for data analysis:</p> In\u00a0[8]: Copied! <pre>human_message = HumanMessage(content=\"How many men survived?\")\n\nasync for event in agent.astream_events(\n    input={\n        # After using checkpoint, you only need to add new messages here.\n        \"messages\": [human_message],\n        \"parent_id\": \"some-parent-id2\",\n        \"date\": date.today(),\n    },\n    version=\"v2\",\n    # We configure the same thread_id to use checkpoints to retrieve the memory of the last run.\n    config={\"configurable\": {\"thread_id\": \"some-thread-id\"}},\n):\n    event_name: str = event[\"name\"]\n    evt: str = event[\"event\"]\n    if evt == \"on_chat_model_end\":\n        print(event[\"data\"][\"output\"])\n    elif event_name == \"tools\" and evt == \"on_chain_stream\":\n        for lc_msg in event[\"data\"][\"chunk\"][\"messages\"]:\n            print(lc_msg)\n    else:\n        # Other events can be handled here.\n        pass\n</pre> human_message = HumanMessage(content=\"How many men survived?\")  async for event in agent.astream_events(     input={         # After using checkpoint, you only need to add new messages here.         \"messages\": [human_message],         \"parent_id\": \"some-parent-id2\",         \"date\": date.today(),     },     version=\"v2\",     # We configure the same thread_id to use checkpoints to retrieve the memory of the last run.     config={\"configurable\": {\"thread_id\": \"some-thread-id\"}}, ):     event_name: str = event[\"name\"]     evt: str = event[\"event\"]     if evt == \"on_chat_model_end\":         print(event[\"data\"][\"output\"])     elif event_name == \"tools\" and evt == \"on_chain_stream\":         for lc_msg in event[\"data\"][\"chunk\"][\"messages\"]:             print(lc_msg)     else:         # Other events can be handled here.         pass  <pre>content=\"\u4e3a\u4e86\u56de\u7b54\u60a8\u7684\u95ee\u9898\uff0c\u6211\u5c06\u7b5b\u9009\u51fa\u6240\u6709\u7537\u6027\u4e58\u5ba2\u5e76\u8ba1\u7b97\u5176\u4e2d\u7684\u5e78\u5b58\u8005\u6570\u91cf\u3002\\n```python\\n# Filter male passengers who survived and count them\\nmale_survivors = df[(df['Sex'] == 'male') &amp; (df['Survived'] == 1)]\\nmale_survivors_count = male_survivors.shape[0]\\nmale_survivors_count\\n```\" additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'TableGPT2-7B'} id='run-661d7496-341d-4a6b-84d8-b4094db66ef0'\ncontent=[{'type': 'text', 'text': '```pycon\\n1\\n```'}] name='python' id='1c7531db-9150-451d-a8dd-f07176454e6f' tool_call_id='2860e8bb-0fa7-421b-bb2d-bfeca873354b' artifact=[]\ncontent='\u6839\u636e\u6570\u636e\u96c6\uff0c\u6709 1 \u540d\u7537\u6027\u4e58\u5ba2\u5e78\u5b58\u3002' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'TableGPT2-7B'} id='run-db640705-0085-4f47-adb4-3e0adce694cd'\n</pre>"},{"location":"tutorials/chat-on-tabular-data/#chat-on-tabular-data","title":"Chat on Tabular Data\u00b6","text":"<p>TableGPT Agent excels at analyzing and processing tabular data. To perform data analysis, you need to first let the agent \"see\" the dataset. This is done by a specific \"file-reading\" workflow. In short, you begin by \"uploading\" the dataset and let the agent read it. Once the data is read, you can ask the agent questions about it.</p> <p>To learn more about the file-reading workflow, see File Reading.</p> <p>For data analysis tasks, we introduce two important parameters when creating the agent: <code>checkpointer</code> and <code>session_id</code>.</p> <ul> <li>The <code>checkpointer</code> should be an instance of <code>langgraph.checkpoint.base.BaseCheckpointSaver</code>, which acts as a versioned \"memory\" for the agent. (See langgraph's persistence concept for more details.)</li> <li>The <code>session_id</code> is a unique identifier for the current session. It ties the agent's execution to a specific kernel, ensuring that the agent's results are retained across multiple invocations.</li> </ul>"},{"location":"tutorials/continue-analysis-on-generated-charts/","title":"Continue Analysis on Generated Charts","text":"In\u00a0[9]: Copied! <pre>from datetime import date\n\n# Define the human message that asks the model to draw a pie chart based on gender data\nhuman_message = HumanMessage(content=\"Draw a pie chart based on gender and the number of people of each gender.\")\n\nasync for event in agent.astream_events(\n    input={\n        \"messages\": [human_message],\n        \"parent_id\": \"some-parent-id2\",\n        \"date\": date.today(),\n    },\n    version=\"v2\",\n    # We configure the same thread_id to use checkpoints to retrieve the memory of the last run.\n    config={\"configurable\": {\"thread_id\": \"some-thread-id\"}},\n):\n    evt = event[\"event\"]\n    if evt == \"on_chat_model_end\":\n        print(event[\"data\"][\"output\"])\n    elif event[\"name\"] == \"tools\" and evt == \"on_chain_stream\":\n        for lc_msg in event[\"data\"][\"chunk\"][\"messages\"]:\n            print(lc_msg)\n    else:\n        # Handle other events here\n        pass\n</pre> from datetime import date  # Define the human message that asks the model to draw a pie chart based on gender data human_message = HumanMessage(content=\"Draw a pie chart based on gender and the number of people of each gender.\")  async for event in agent.astream_events(     input={         \"messages\": [human_message],         \"parent_id\": \"some-parent-id2\",         \"date\": date.today(),     },     version=\"v2\",     # We configure the same thread_id to use checkpoints to retrieve the memory of the last run.     config={\"configurable\": {\"thread_id\": \"some-thread-id\"}}, ):     evt = event[\"event\"]     if evt == \"on_chat_model_end\":         print(event[\"data\"][\"output\"])     elif event[\"name\"] == \"tools\" and evt == \"on_chain_stream\":         for lc_msg in event[\"data\"][\"chunk\"][\"messages\"]:             print(lc_msg)     else:         # Handle other events here         pass <pre>content=\"\u597d\u7684\uff0c\u6211\u5c06\u57fa\u4e8e\u6027\u522b\u7ed8\u5236\u4e00\u4e2a\u997c\u56fe\uff0c\u4ee5\u5c55\u793a\u6bcf\u4e2a\u6027\u522b\u7684\u4eba\u6570\u3002\u9996\u5148\uff0c\u6211\u4eec\u9700\u8981\u7edf\u8ba1\u6bcf\u4e2a\u6027\u522b\u7684\u4eba\u6570\uff0c\u7136\u540e\u4f7f\u7528 `seaborn` \u548c `matplotlib` \u6765\u7ed8\u5236\u997c\u56fe\u3002\\n\\n```python\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# Count the number of people for each gender\\ngender_counts = df['Sex'].value_counts()\\n\\n# Create a pie chart\\nplt.figure(figsize=(8, 6))\\nplt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))\\nplt.title('Gender Distribution')\\nplt.show()\\n```\" additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'TableGPT2-7B'} id='run-6115fe22-3b55-4d85-be09-6c31a59736f6'\ncontent=[{'type': 'text', 'text': '```pycon\\n&lt;Figure size 800x600 with 1 Axes&gt;\\n```'}, {'type': 'image_url', 'image_url': {'url': 'data:image/png;base64,iVBORw0KG...'}}] name='python' id='226ba8f2-29a7-4706-9178-8cb5b4062488' tool_call_id='03eb1113-6aed-4e0a-a3c0-4cc0043a55ee' artifact=[]\ncontent='\u997c\u56fe\u5df2\u7ecf\u6210\u529f\u751f\u6210\u3002' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'TableGPT2-7B'} id='run-83468bd1-9451-4c78-91a3-b0f96ffa169a'\n</pre> <p>Now let's set up the Visual Language Model (VLM) and create a new agent with VLM support:</p> In\u00a0[10]: Copied! <pre># Initialize the VLM instance\nvlm = ChatOpenAI(openai_api_base=\"YOUR_VLM_URL\", openai_api_key=\"whatever\", model_name=\"YOUR_MODEL_NAME\")\n\n# Assume llm, pybox_manager, and memory_saver are defined elsewhere\nagent_with_vlm = create_tablegpt_graph(\n    llm=llm,\n    pybox_manager=pybox_manager,\n    vlm=vlm,\n    checkpointer=checkpointer,\n    session_id=\"some-session-id\",\n)\n</pre> # Initialize the VLM instance vlm = ChatOpenAI(openai_api_base=\"YOUR_VLM_URL\", openai_api_key=\"whatever\", model_name=\"YOUR_MODEL_NAME\")  # Assume llm, pybox_manager, and memory_saver are defined elsewhere agent_with_vlm = create_tablegpt_graph(     llm=llm,     pybox_manager=pybox_manager,     vlm=vlm,     checkpointer=checkpointer,     session_id=\"some-session-id\", ) <p>We use a time travel feature to go back to before the last time the agent gave an answer, to avoid past memories hallucinating the model:</p> In\u00a0[11]: Copied! <pre>state_history = agent.get_state_history(config={\"configurable\": {\"thread_id\": \"some-thread-id\"}})\n\nto_replay = None\nfor state in list(state_history)[::-1]:\n    if state.next and state.next[0] == \"__start__\":\n        to_replay = state\n</pre> state_history = agent.get_state_history(config={\"configurable\": {\"thread_id\": \"some-thread-id\"}})  to_replay = None for state in list(state_history)[::-1]:     if state.next and state.next[0] == \"__start__\":         to_replay = state <p>Send the same question to the model via the new agent with VLM support</p> In\u00a0[12]: Copied! <pre>async for event in agent_with_vlm.astream_events(\n    None,\n    to_replay.config,\n    version=\"v2\",\n):\n    evt = event[\"event\"]\n    if evt == \"on_chat_model_end\":\n        print(event[\"data\"][\"output\"])\n    elif event[\"name\"] == \"tools\" and evt == \"on_chain_stream\":\n        for lc_msg in event[\"data\"][\"chunk\"][\"messages\"]:\n            print(lc_msg)\n    else:\n        # Handle other events here\n        pass\n</pre> async for event in agent_with_vlm.astream_events(     None,     to_replay.config,     version=\"v2\", ):     evt = event[\"event\"]     if evt == \"on_chat_model_end\":         print(event[\"data\"][\"output\"])     elif event[\"name\"] == \"tools\" and evt == \"on_chain_stream\":         for lc_msg in event[\"data\"][\"chunk\"][\"messages\"]:             print(lc_msg)     else:         # Handle other events here         pass <pre>content=\"\u597d\u7684\uff0c\u6211\u5c06\u7ed8\u5236\u4e00\u4e2a\u997c\u56fe\u6765\u5c55\u793a\u6570\u636e\u96c6\u4e2d\u7537\u6027\u548c\u5973\u6027\u4e58\u5ba2\u7684\u6570\u91cf\u3002\\n```python\\n# Count the number of passengers by gender\\ngender_counts = df['Sex'].value_counts()\\n\\n# Plot a pie chart\\nplt.figure(figsize=(8, 6))\\nplt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=140)\\nplt.title('Gender Distribution')\\nplt.show()\\n```\\n\" additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'TableGPT2-7B'} id='run-2d05b2ab-32f4-481f-8fa5-43c78515d9c3'\ncontent=[{'type': 'text', 'text': '```pycon\\n&lt;Figure size 800x600 with 1 Axes&gt;\\n```'}, {'type': 'image_url', 'image_url': {'url': 'data:image/png;base64,iVBORw0K...'}}] name='python' id='51a99935-b0b1-496d-9a45-c1f318104773' tool_call_id='918d57ee-7362-4e0d-8d66-64b7e57ecaf6' artifact=[]\ncontent='\u997c\u56fe\u663e\u793a\u6570\u636e\u96c6\u4e2d\u6027\u522b\u5206\u5e03\u4e3a 50% \u5973\u6027\u548c 50% \u7537\u6027\uff0c\u8fd9\u8868\u660e\u7537\u6027\u548c\u5973\u6027\u4e58\u5ba2\u6570\u91cf\u76f8\u7b49\u3002' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen2-vl-7b-instruct'} id='run-d9b0e891-f03c-40c8-8474-9fef7511c40b'\n</pre> <p>We observe that the answer provided by the agent with VLM support is significantly more detailed, including a comprehensive description of the generated images.</p>"},{"location":"tutorials/continue-analysis-on-generated-charts/#continue-analysis-on-generated-charts","title":"Continue Analysis on Generated Charts\u00b6","text":"<p>While TableGPT2 excels in data analysis tasks, it currently lacks built-in support for visual modalities. Many data analysis tasks involve visualization, so to address this limitation, we provide an interface for integrating your own Visual Language Model (VLM) plugin.</p> <p>When the agent performs a visualization task\u2014typically using <code>matplotlib.pyplot.show</code>\u2014the VLM will take over from the LLM, offering a more nuanced summarization of the visualization. This approach avoids the common pitfalls of LLMs in visualization tasks, which often either state, \"I have plotted the data,\" or hallucinating the content of the plot.</p> <p>We continue using the agent from the previous section to perform a data visualization task and observe its final output.</p> <p>NOTE Before you start, you can install Chinese fonts using the following command:</p> <pre>apt-get update &amp;&amp; apt-get install -y --no-install-recommends fonts-noto-cjk\nmplfonts init\n</pre>"},{"location":"tutorials/quick-start/","title":"Quickstart","text":"In\u00a0[\u00a0]: Copied! <pre>%pip install tablegpt-agent\n</pre> %pip install tablegpt-agent <p>This package depends on pybox to manage code execution environment. By default, pybox operates in an in-cluster mode. If you intend to run tablegpt-agent in a local environment, install the optional dependency as follows:</p> In\u00a0[1]: Copied! <pre>%pip install tablegpt-agent[local]\n</pre> %pip install tablegpt-agent[local] <p>In the console or notebook, set the proxy as follows:</p> In\u00a0[2]: Copied! <pre>from langchain_openai import ChatOpenAI\nfrom pybox import LocalPyBoxManager\nfrom tablegpt.agent import create_tablegpt_graph\n\nPROFILE_DIR = '/home/jovyan/.local/share/ipykernel/profile/tablegpt/startup'\nllm = ChatOpenAI(openai_api_base=\"YOUR_VLLM_URL\", openai_api_key=\"whatever\", model_name=\"TableGPT2-7B\")\npybox_manager = LocalPyBoxManager(profile_dir=PROFILE_DIR)\n\nagent = create_tablegpt_graph(\n    llm=llm,\n    pybox_manager=pybox_manager,\n)\n</pre> from langchain_openai import ChatOpenAI from pybox import LocalPyBoxManager from tablegpt.agent import create_tablegpt_graph  PROFILE_DIR = '/home/jovyan/.local/share/ipykernel/profile/tablegpt/startup' llm = ChatOpenAI(openai_api_base=\"YOUR_VLLM_URL\", openai_api_key=\"whatever\", model_name=\"TableGPT2-7B\") pybox_manager = LocalPyBoxManager(profile_dir=PROFILE_DIR)  agent = create_tablegpt_graph(     llm=llm,     pybox_manager=pybox_manager, ) <p>To interact with the agent:</p> In\u00a0[3]: Copied! <pre>from datetime import date\nfrom langchain_core.messages import HumanMessage\n\nmessage = HumanMessage(content=\"Hi\")\n\n_input = {\n    \"messages\": [message],\n    \"parent_id\": \"some-parent-id\",\n    \"date\": date.today(),\n}\n\nresponse = await agent.ainvoke(_input)\nresponse[\"messages\"]\n</pre> from datetime import date from langchain_core.messages import HumanMessage  message = HumanMessage(content=\"Hi\")  _input = {     \"messages\": [message],     \"parent_id\": \"some-parent-id\",     \"date\": date.today(), }  response = await agent.ainvoke(_input) response[\"messages\"] <pre>[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='34fe748c-81ab-49ea-bec6-9c621598a61a'), AIMessage(content=\"Hello! How can I assist you with data analysis today? Please let me know the details of the dataset you're working with and what specific analysis you'd like to perform.\", additional_kwargs={'parent_id': 'some-parent-id'}, response_metadata={}, id='a1ee29d2-723e-41c7-b420-27d0cfaed5dc')]\n</pre> <p>You can get more detailed outputs with the <code>astream_events</code> method:</p> In\u00a0[4]: Copied! <pre>async for event in agent.astream_events(\n    input=_input,\n    version=\"v2\",\n):\n    # We ignore irrelevant events here.\n    if event[\"event\"] == \"on_chat_model_end\":\n        print(event[\"data\"][\"output\"])\n</pre> async for event in agent.astream_events(     input=_input,     version=\"v2\", ):     # We ignore irrelevant events here.     if event[\"event\"] == \"on_chat_model_end\":         print(event[\"data\"][\"output\"]) <pre>content='Hello! How can I assist you with your data analysis today? Please let me know what dataset you are working with and what specific analyses or visualizations you would like to perform.' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'TableGPT2-7B'} id='run-525eb149-0e3f-4b04-868b-708295f789ac'\n</pre>"},{"location":"tutorials/quick-start/#quickstart","title":"Quickstart\u00b6","text":""},{"location":"tutorials/quick-start/#installation","title":"Installation\u00b6","text":"<p>To install TableGPT Agent, use the following command:</p>"},{"location":"tutorials/quick-start/#setup-the-llm-service","title":"Setup the LLM Service\u00b6","text":"<p>Before using TableGPT Agent, ensure you have an OpenAI-compatible server configured to host TableGPT2. We recommend using vllm for this:</p> <pre>python -m vllm.entrypoints.openai.api_server --served-model-name TableGPT2-7B --model path/to/weights\n</pre> <p>Notes:</p> <ul> <li>To analyze tabular data with <code>tablegpt-agent</code>, make sure <code>TableGPT2</code> is served with <code>vllm</code> version 0.5.5 or higher.</li> <li>For production environments, it's important to optimize the vllm server configuration. For details, refer to the vllm documentation on server configuration.</li> </ul>"},{"location":"tutorials/quick-start/#chat-with-tablegpt-agent","title":"Chat with TableGPT Agent\u00b6","text":"<p>To create an agent, you'll need at least an <code>LLM</code> instance and a <code>PyBoxManager</code>:</p> <p>NOTE 1: This tutorial uses <code>langchain-openai</code> for the llm instance. Please install it first.</p> <pre>pip install langchain-openai\n</pre> <p>NOTE 2: TableGPT Agent fully supports aync invocation. To start a Python console that supports asynchronous operations, run the following command:</p> <pre>python -m asyncio\n</pre>"}]}